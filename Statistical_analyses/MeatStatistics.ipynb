{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf53942f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict \n",
    "from collections import Counter\n",
    "from os import walk\n",
    "\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import math\n",
    "import statistics\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import re\n",
    "\n",
    "from scipy import stats\n",
    "import math\n",
    "import statistics\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30415b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496\n"
     ]
    }
   ],
   "source": [
    "data_path = \"./LLM_Scored/run_config/\"\n",
    "filenames = list(set(next(walk(data_path), (None,None,[]))[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b149469c",
   "metadata": {},
   "source": [
    "## Number of recipes and average token length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "702a3a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:14<00:00, 33.82it/s]\n"
     ]
    }
   ],
   "source": [
    "total_count = 0.\n",
    "coutn_eng = 0.\n",
    "count_long = 0.\n",
    "avg_len = []\n",
    "for k in tqdm(range(len(filenames))):\n",
    "    recette = filenames[k]\n",
    "    file_path = data_path + recette\n",
    "    with open(file_path) as json_file:\n",
    "        recipe_dict = json.load(json_file)\n",
    "\n",
    "    country_orig = recipe_dict['Country']\n",
    "    base_ingredient_list = recipe_dict['Reference_Base']['AllIngredients']\n",
    "\n",
    "\n",
    "    if 'same_country_novelty' in recipe_dict['LLM_gen']:\n",
    "        llm_recipe_ids = list(recipe_dict['LLM_gen']['same_country_novelty'].keys())\n",
    "        for recipe in llm_recipe_ids:\n",
    "            recipe_ = recipe_dict['LLM_gen']['same_country_novelty'][recipe]['Instructions']\n",
    "            title = recipe_dict['LLM_gen']['same_country_novelty'][recipe]['Title']\n",
    "            ingredients = recipe_dict['LLM_gen']['same_country_novelty'][recipe]['Ingredients']\n",
    "            avg_len.append(len(recipe_.split()) + len(title.split()) + len(ingredients))\n",
    "\n",
    "    varia_countries = list(recipe_dict['LLM_gen']['variation_novelty'].keys())\n",
    "    for varia in varia_countries:\n",
    "        llm_recipe_varia_ids = list(recipe_dict['LLM_gen']['variation_novelty'][varia].keys())\n",
    "        for i in range(len(llm_recipe_varia_ids)):\n",
    "            recipe_ = recipe_dict['LLM_gen']['variation_novelty'][varia][llm_recipe_varia_ids[i]]['Instructions']\n",
    "            title = recipe_dict['LLM_gen']['variation_novelty'][varia][llm_recipe_varia_ids[i]]['Title']\n",
    "            ingredients = recipe_dict['LLM_gen']['variation_novelty'][varia][llm_recipe_varia_ids[i]]['Ingredients']\n",
    "            avg_len.append(len(recipe_.split())+ len(title.split()) + len(ingredients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54ae481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196116\n",
      "AVG Recipe LENGTH :  274.0281160129719\n"
     ]
    }
   ],
   "source": [
    "print('Number of recipes : ', len(avg_len))\n",
    "print('AVG Recipe LENGTH : ', sum(avg_len)/len(avg_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c63832",
   "metadata": {},
   "source": [
    "## Measure the divergence in ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdef4224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e387b67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ingr(ingredient, authorized_pos=['NOUN']):\n",
    "\n",
    "    doc = nlp(ingredient)\n",
    "    token_list = [token.text for token in doc if token.pos_ in authorized_pos]\n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3b84432",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_region = {\"Asia\": [\"china\", \"mongolia\", \"india\", \"japan\", \"thailand\", \"vietnam\", \"singapore\", \"malaysia\", \"south korea\", \"pakistan\", \"philippines\", \"indonesia\", \"taiwan\", \"bangladesh\", \"cambodia\", \"uzbekistan\", \"azerbaijan\"], \n",
    "\"North America\": [\"united states\", \"mexico\", \"canada\"], \"Europe\":[\"italy\", \"spain\", \"france\", \"switzerland\", \"hungary\", \"greece\", \"norway\", \"portugal\", \"russia\", \"sweden\", \"ireland\", \"germany\", \"romania\", \"finland\", \"belgium\", \"denmark\", \"slovakia\", \"netherlands\", \"guernsey\", \"luxembourg\", \"bulgaria\", \"lithuania\", \"armenia\", \"poland\", \"austria\", \"albania\", \"serbia\", \"moldova\", \"czech republic\", \"united kingdom\", \"liechtenstein\", \"latvia\", \"croatia\", \"macedonia\", \"ukraine\", \"belarus\", \"estonia\", \"bosnia and herzegovina\", \"malta\", \"cyprus\", \"iceland\", \"georgia\"],\n",
    "\"Oceania\":[\"australia\", \"fiji\", \"haiti\", \"brunei\", \"micronesia\", \"samoa\", \"tonga\", \"guam\"], \"South America\": [\"peru\", \"brazil\", \"panama\", \"bolivia\", \"uruguay\", \"el salvador\", \"colombia\", \"argentina\", \"paraguay\", \"nicaragua\", \"venezuela\", \"guatemala\", \"guyana\", \"ecuador\", \"honduras\"], \n",
    "\"Carribean\": [\"cuba\", \"jamaica\", \"trinidad and tobago\", \"barbados\", \"bermuda\", \"belize\", \"antigua and barbuda\", \"bahamas\", \"dominican republic\", \"grenada\", \"curaçao\"],\n",
    "\"East Asia\": [\"israel\",  \"palestinian territories\", \"turkiye\", \"lebanon\", \"afghanistan\", \"tunisia\", \"iraq\", \"iran\", \"qatar\", \"syria\", \"jordan\", \"oman\", \"bahrain\", \"yemen\"],\n",
    "\"Africa\": [\"egypt\", \"morocco\", \"algeria\", \"ethiopia\", \"guinea\", \"mauritius\", \"madagascar\", \"chad\", \"mozambique\", \"senegal\", \"kenya\", \"libya\", \"cote d’ivoire\", \"ghana\", \"angola\", \"mauritania\", \"nigeria\", \"congo\", \"liberia\"]}\n",
    "\n",
    "country_to_region = {country: region for region, countries in dict_region.items() for country in countries}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3cb2ac",
   "metadata": {},
   "source": [
    "We measure the proportion of new ingredients in these recipes that are also present in basic recipes, compared to humans as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08919868",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [21:29<00:00,  2.57s/it]\n"
     ]
    }
   ],
   "source": [
    "prop_HiR, prop_RiH, prop_LiR, prop_RiL = [],[],[],[]\n",
    "for k in tqdm(range(len(filenames))):\n",
    "    recette = filenames[k]\n",
    "    file_path = data_path + recette\n",
    "    with open(file_path) as json_file:\n",
    "        recipe_dict = json.load(json_file)\n",
    "\n",
    "    country_orig = recipe_dict['Country']\n",
    "    base_ingredient_list = recipe_dict['Reference_Base']['AllIngredients']\n",
    "\n",
    "    LLM_ingredient_list = []\n",
    "    human_ingredient_list = []\n",
    "    if 'same_country_novelty' in recipe_dict['LLM_gen']:\n",
    "        llm_recipe_ids = list(recipe_dict['LLM_gen']['same_country_novelty'].keys())\n",
    "        for recipe in llm_recipe_ids:\n",
    "            ingredient_list = recipe_dict['LLM_gen']['same_country_novelty'][recipe]['Ingredients']\n",
    "            for ingredient in ingredient_list:\n",
    "                LLM_ingredient_list.extend(clean_ingr(ingredient))\n",
    "\n",
    "    valid_recipe_ids = list(recipe_dict['Valid_Variations'].keys())\n",
    "    for i in range(len(valid_recipe_ids)):\n",
    "        if recipe_dict['Valid_Variations'][valid_recipe_ids[i]]['country'] == country_orig:\n",
    "            ingredient_valid = recipe_dict['Valid_Variations'][valid_recipe_ids[i]]['ingredient_list']\n",
    "            for ingredient in ingredient_valid:\n",
    "                human_ingredient_list.extend(clean_ingr(ingredient))\n",
    "    \n",
    "    test_recipe_ids = list(recipe_dict['Test_Variations'].keys())\n",
    "    for i in range(len(test_recipe_ids)):\n",
    "        if recipe_dict['Test_Variations'][test_recipe_ids[i]]['country'] == country_orig:\n",
    "            ingredient_test = recipe_dict['Test_Variations'][test_recipe_ids[i]]['ingredient_list']\n",
    "            for ingredient in ingredient_valid:\n",
    "                human_ingredient_list.extend(clean_ingr(ingredient))\n",
    "\n",
    "    if len(human_ingredient_list) >0:\n",
    "        human_ingredient_list = list(set(human_ingredient_list))\n",
    "        human_in_ref = sum(1 for item in human_ingredient_list if item in base_ingredient_list)\n",
    "        prop_HiR.append(human_in_ref / len(human_ingredient_list))\n",
    "        ref_in_human = sum(1 for item in base_ingredient_list if item in human_ingredient_list)\n",
    "        prop_RiH.append(ref_in_human / len(base_ingredient_list))\n",
    "    else:\n",
    "        prop_HiR.append(0.)\n",
    "        prop_RiH.append(0.)\n",
    "    if len(LLM_ingredient_list) >0:\n",
    "        LLM_ingredient_list = list(set(LLM_ingredient_list))\n",
    "        LLM_in_ref = sum(1 for item in LLM_ingredient_list if item in base_ingredient_list)\n",
    "        prop_LiR.append(LLM_in_ref / len(LLM_ingredient_list))\n",
    "        ref_in_LLM = sum(1 for item in base_ingredient_list if item in LLM_ingredient_list)\n",
    "        prop_RiL.append(ref_in_LLM / len(base_ingredient_list))\n",
    "    else:\n",
    "        prop_LiR.append(0.)\n",
    "        prop_RiL.append(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40261941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Human in base: 0.9959826655934441 Mean Base in Human: 0.9999189378295624 Mean LLM in base: 0.9334478646658051 Mean Base in LLM: 0.7904652996228437\n"
     ]
    }
   ],
   "source": [
    "prop_HiR = np.array(prop_HiR)\n",
    "prop_RiH = np.array(prop_RiH)\n",
    "prop_LiR = np.array(prop_LiR)\n",
    "prop_RiL = np.array(prop_RiL)\n",
    "\n",
    "# Step 1: Mean values\n",
    "mean_HiR, mean_RiH, mean_LiR, mean_RiL = np.mean(prop_HiR), np.mean(prop_RiH), np.mean(prop_LiR), np.mean(prop_RiL)\n",
    "print(\"Mean Human in base:\", 1 - mean_HiR, \"Mean Base in Human:\", 1-mean_RiH, \"Mean LLM in base:\", 1-mean_LiR, \"Mean Base in LLM:\", 1-mean_RiL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fcd03d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 496/496 [04:02<00:00,  2.05it/s]\n"
     ]
    }
   ],
   "source": [
    "## Doing it by region\n",
    "prop_LiR, prop_RiL = {}, {}\n",
    "\n",
    "for k in tqdm(range(len(filenames))):\n",
    "    recette = filenames[k]\n",
    "    file_path = data_path + recette\n",
    "    with open(file_path) as json_file:\n",
    "        recipe_dict = json.load(json_file)\n",
    "\n",
    "    country_orig = recipe_dict['Country']\n",
    "    base_ingredient_list = recipe_dict['Reference_Base']['AllIngredients']\n",
    "\n",
    "    if country_orig in country_to_region.keys():\n",
    "        region = country_to_region.get(country_orig)\n",
    "    else:\n",
    "        region = 'UNK'\n",
    "\n",
    "    LLM_ingredient_list = []\n",
    "    human_ingredient_list = []\n",
    "    if 'same_country_novelty' in recipe_dict['LLM_gen']:\n",
    "        llm_recipe_ids = list(recipe_dict['LLM_gen']['same_country_novelty'].keys())\n",
    "        for recipe in llm_recipe_ids:\n",
    "            ingredient_list = recipe_dict['LLM_gen']['same_country_novelty'][recipe]['Ingredients']\n",
    "            for ingredient in ingredient_list:\n",
    "                LLM_ingredient_list.extend(clean_ingr(ingredient))\n",
    "\n",
    "\n",
    "    if len(LLM_ingredient_list) > 0:\n",
    "        LLM_ingredient_list = list(set(LLM_ingredient_list))\n",
    "        LLM_in_ref = sum(1 for item in LLM_ingredient_list if item in base_ingredient_list)\n",
    "        if region not in prop_LiR.keys():\n",
    "            prop_LiR[region] = []\n",
    "        \n",
    "        prop_LiR[region].append(LLM_in_ref / len(LLM_ingredient_list))\n",
    "        \n",
    "        ref_in_LLM = sum(1 for item in base_ingredient_list if item in LLM_ingredient_list)\n",
    "        if region not in prop_RiL.keys():\n",
    "            prop_RiL[region] = []\n",
    "        prop_RiL[region].append(ref_in_LLM / len(base_ingredient_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32685d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean LLM in base: 0.627067873664686 Mean Base in LLM: 0.8875215797678363\n"
     ]
    }
   ],
   "source": [
    "## Regions  Asia | Europe | North America | Oceania | South America | Carribean | East Asia | Africa\n",
    "region = \"Asia\"\n",
    "prop_LiR_Regional = np.array(prop_LiR[region])\n",
    "prop_RiL_Regional = np.array(prop_RiL[region])\n",
    "\n",
    "# Step 1: Mean values\n",
    "mean_LiR, mean_RiL =  np.mean(prop_LiR_Regional), np.mean(prop_RiL_Regional)\n",
    "print(\"Mean LLM in base:\", 1-mean_LiR, \"Mean Base in LLM:\", 1-mean_RiL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60754b58",
   "metadata": {},
   "source": [
    "## Counting the number of time ingredients list is used in instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11323df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [06:26<00:00,  1.30it/s]\n"
     ]
    }
   ],
   "source": [
    "prop_ingr_in_instr = []\n",
    "for k in tqdm(range(len(filenames))):\n",
    "    recette = filenames[k]\n",
    "    file_path = data_path + recette\n",
    "    with open(file_path) as json_file:\n",
    "        recipe_dict = json.load(json_file)\n",
    "    \n",
    "    country_orig = recipe_dict['Country']\n",
    "    base_ingredient_list = recipe_dict['Reference_Base']['AllIngredients']\n",
    "    if 'same_country_novelty' in recipe_dict['LLM_gen']:\n",
    "        llm_recipe_ids = list(recipe_dict['LLM_gen']['same_country_novelty'].keys())\n",
    "        for recipe in llm_recipe_ids:\n",
    "            count_in_instructions = 0\n",
    "            ingredient_list = recipe_dict['LLM_gen']['same_country_novelty'][recipe]['Ingredients']\n",
    "            individual_ingredient = []\n",
    "            for ingredient in ingredient_list:\n",
    "                individual_ingredient.extend(clean_ingr(ingredient))\n",
    "\n",
    "            recipe = recipe_dict['LLM_gen']['same_country_novelty'][recipe]['Instructions']\n",
    "            \n",
    "            for ingredient in individual_ingredient:\n",
    "                if ingredient in recipe:\n",
    "                    count_in_instructions += 1\n",
    "            \n",
    "            if len(individual_ingredient) > 0:\n",
    "                individual_ingredient = list(set(individual_ingredient))\n",
    "                prop_ingr_in_instr.append(count_in_instructions / len(individual_ingredient))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fed761f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Ingre in Instructions Same country: 0.5901024763876807\n"
     ]
    }
   ],
   "source": [
    "prop_ingr_in_instr  = np.array(prop_ingr_in_instr)\n",
    "mean_IiI = np.mean(prop_ingr_in_instr)\n",
    "print(\"Mean Ingre in Instructions Same country:\", mean_IiI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "405783d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [1:08:22<00:00,  8.19s/it]\n"
     ]
    }
   ],
   "source": [
    "prop_ingr_in_instr = []\n",
    "for k in tqdm(range(len(filenames))):\n",
    "    recette = filenames[k]\n",
    "    file_path = data_path + recette\n",
    "    with open(file_path) as json_file:\n",
    "        recipe_dict = json.load(json_file)\n",
    "    \n",
    "    country_orig = recipe_dict['Country']\n",
    "    base_ingredient_list = recipe_dict['Reference_Base']['AllIngredients']\n",
    "\n",
    "\n",
    "    varia_countries = list(recipe_dict['LLM_gen']['variation_novelty'].keys())\n",
    "    for varia in varia_countries:\n",
    "        llm_recipe_varia_ids = list(recipe_dict['LLM_gen']['variation_novelty'][varia].keys())\n",
    "        for i in range(len(llm_recipe_varia_ids)):\n",
    "            count_in_instructions = 0\n",
    "            ingredient_list = recipe_dict['LLM_gen']['variation_novelty'][varia][llm_recipe_varia_ids[i]]['Ingredients']\n",
    "            for ingredient in ingredient_list:\n",
    "                individual_ingredient.extend(clean_ingr(ingredient))\n",
    "                \n",
    "            recipe = recipe_dict['LLM_gen']['variation_novelty'][varia][llm_recipe_varia_ids[i]]['Instructions']\n",
    "\n",
    "            for ingredient in individual_ingredient:\n",
    "                if ingredient in recipe:\n",
    "                    count_in_instructions += 1\n",
    "            \n",
    "            if len(individual_ingredient) > 0:\n",
    "                individual_ingredient = list(set(individual_ingredient))\n",
    "                prop_ingr_in_instr.append(count_in_instructions / len(individual_ingredient))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7078c1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Ingre in Instructions Varia country: 0.019365754640101804\n"
     ]
    }
   ],
   "source": [
    "prop_ingr_in_instr  = np.array(prop_ingr_in_instr)\n",
    "mean_IiI = np.mean(prop_ingr_in_instr)\n",
    "print(\"Mean Ingre in Instructions Varia country:\", mean_IiI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c95a546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Ingre in Instructions Varia country: 0.3415972864592488\n"
     ]
    }
   ],
   "source": [
    "prop_2  = np.array(prop_ingr_in_instr[0:100])\n",
    "mean_IiI = np.mean(prop_2)\n",
    "print(\"Mean Ingre in Instructions Varia country:\", mean_IiI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0501af",
   "metadata": {},
   "source": [
    "## Counting non-english and too short instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18f873b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46ed5508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90e279e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(recette, thrs=50):\n",
    "    list_recette = recette.split()\n",
    "    if len(list_recette) > thrs:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90d9abb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [21:48<00:00,  2.61s/it]\n"
     ]
    }
   ],
   "source": [
    "total_count = 0.\n",
    "coutn_eng = 0.\n",
    "count_long = 0.\n",
    "for k in tqdm(range(len(filenames))):\n",
    "    recette = filenames[k]\n",
    "    file_path = data_path + recette\n",
    "    with open(file_path) as json_file:\n",
    "        recipe_dict = json.load(json_file)\n",
    "\n",
    "    country_orig = recipe_dict['Country']\n",
    "    base_ingredient_list = recipe_dict['Reference_Base']['AllIngredients']\n",
    "\n",
    "    LLM_ingredient_list = []\n",
    "    if 'same_country_novelty' in recipe_dict['LLM_gen']:\n",
    "        llm_recipe_ids = list(recipe_dict['LLM_gen']['same_country_novelty'].keys())\n",
    "        for recipe in llm_recipe_ids:\n",
    "            recipe = recipe_dict['LLM_gen']['same_country_novelty'][recipe]['Instructions']\n",
    "            if is_english(recipe):\n",
    "                coutn_eng += 1\n",
    "            if count_tokens(recipe):\n",
    "                count_long +=1 \n",
    "            total_count += 1\n",
    "    \n",
    "    varia_countries = list(recipe_dict['LLM_gen']['variation_novelty'].keys())\n",
    "    for varia in varia_countries:\n",
    "        llm_recipe_varia_ids = list(recipe_dict['LLM_gen']['variation_novelty'][varia].keys())\n",
    "        for i in range(len(llm_recipe_varia_ids)):\n",
    "            recipe = recipe_dict['LLM_gen']['variation_novelty'][varia][llm_recipe_varia_ids[i]]['Instructions']\n",
    "            if is_english(recipe):\n",
    "                coutn_eng += 1\n",
    "            if count_tokens(recipe):\n",
    "                count_long +=1 \n",
    "            total_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20fdbf83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb tot recipes :  196116.0\n",
      "Prop_eng :  0.9572038997328112\n",
      "Prop more than 50 tokens :  0.9712568071957413\n"
     ]
    }
   ],
   "source": [
    "print('Nb tot recipes : ', total_count)\n",
    "print('Prop_eng : ', coutn_eng/total_count)\n",
    "print('Prop more than 50 tokens : ', count_long/total_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded50ccb",
   "metadata": {},
   "source": [
    "## Counting when country is explicitely not in the countru of origin or the variation asked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5e7790d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fed4f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df = pd.read_csv('/home/mila/f/florian.carichon/scratch/Cultural_Datasets/countries.csv')\n",
    "lower_countries_df = country_df.assign(nat_lower=country_df['Nationality'].str.strip().str.lower())\n",
    "lower_countries_df = lower_countries_df.assign(country_lower=country_df['Name'].str.strip().str.lower())\n",
    "nat_to_country = lower_countries_df.drop_duplicates('nat_lower').set_index('nat_lower')['Name'].to_dict()\n",
    "\n",
    "country_list = list(lower_countries_df['Name'])\n",
    "country_list_lower = list(lower_countries_df['country_lower'])\n",
    "\n",
    "nationalty_list = list(lower_countries_df['Nationality'])\n",
    "nationalty_list_lower = list(lower_countries_df['nat_lower'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73afd96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:20<00:00, 24.30it/s]\n"
     ]
    }
   ],
   "source": [
    "dict_orig = {}\n",
    "same_orig_tradi = 0\n",
    "same_varia = 0\n",
    "tot_count = 0\n",
    "\n",
    "for k in tqdm(range(len(filenames))):\n",
    "    recette = filenames[k]\n",
    "    file_path = data_path + recette\n",
    "    with open(file_path) as json_file:\n",
    "        recipe_dict = json.load(json_file)\n",
    "\n",
    "    country_orig = recipe_dict['Country'].lower()\n",
    "    if 'same_country_novelty' in recipe_dict['LLM_gen']:\n",
    "        same_novelty_dict = recipe_dict['LLM_gen']['same_country_novelty']\n",
    "        same_key_list = list(same_novelty_dict.keys())\n",
    "\n",
    "        final_count_list = []\n",
    "        for key in same_key_list:\n",
    "            if \"basic\" in key.lower():          #those are the recipes where I don't mention the country of origin\n",
    "                title = same_novelty_dict[key]['Title']\n",
    "                tokens = re.findall(r'\\b\\w+\\b', title.lower())\n",
    "                matches_countries = [token for token in tokens if token in country_list_lower]\n",
    "                matches_nat = [token for token in tokens if token in nationalty_list_lower]\n",
    "                matches_countries = matches_countries + [nat_to_country.get(nat.strip().lower()) for nat in matches_nat]\n",
    "                final_count_list.extend(matches_countries)\n",
    "            else:\n",
    "                title = same_novelty_dict[key]['Title']\n",
    "                tokens = re.findall(r'\\b\\w+\\b', title.lower())\n",
    "                matches_countries = [token for token in tokens if token in country_list_lower]\n",
    "                matches_nat = [token for token in tokens if token in nationalty_list_lower]\n",
    "                matches_countries = matches_countries + [nat_to_country.get(nat.strip().lower()) for nat in matches_nat]\n",
    "                if len(matches_countries) == 0:\n",
    "                    same_varia += 1\n",
    "                    tot_count += 1\n",
    "                else:\n",
    "                    for country in matches_countries:\n",
    "                        if country == country_orig:\n",
    "                            same_varia += 1\n",
    "                        tot_count += 1\n",
    "\n",
    "        if len(final_count_list) > 0:\n",
    "            count_dict = dict(Counter(final_count_list))\n",
    "            most_common_country = max(count_dict, key=count_dict.get)\n",
    "            dict_orig[country_orig] = most_common_country.lower()\n",
    "            if most_common_country.lower() == country_orig:\n",
    "                same_orig_tradi += 1\n",
    "        \n",
    "\n",
    "    varia_novelty_dict = recipe_dict['LLM_gen']['variation_novelty']\n",
    "    varia_country_keys = list(varia_novelty_dict.keys())\n",
    "\n",
    "    for varia_country in varia_country_keys:\n",
    "        country_v = varia_country.split(\"_\", 1)[1]\n",
    "        key_list = list(varia_novelty_dict[varia_country].keys())\n",
    "        for key in key_list:\n",
    "            title = varia_novelty_dict[varia_country][key]['Title']\n",
    "            tokens = re.findall(r'\\b\\w+\\b', title.lower())\n",
    "            matches_countries = [token for token in tokens if token in country_list_lower]\n",
    "            matches_nat = [token for token in tokens if token in nationalty_list_lower]\n",
    "            matches_countries = matches_countries + [nat_to_country.get(nat.strip().lower()) for nat in matches_nat]\n",
    "            if len(matches_countries) == 0:\n",
    "                same_varia += 1\n",
    "                tot_count += 1\n",
    "            else:\n",
    "                for country in matches_countries:\n",
    "                    if country == country_orig:\n",
    "                        same_varia += 1\n",
    "                    tot_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be7a5acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131848 203577 0.6476566606247267\n",
      "179 0.6391129032258065\n",
      "{'italy': 'italy', 'china': 'south korea', 'mexico': 'cuba', 'lebanon': 'morocco', 'russia': 'russia', 'germany': 'pennsylvania', 'cuba': 'cuba', 'india': 'india', 'netherlands': 'netherlands', 'greece': 'greece', 'morocco': 'south korea', 'ukraine': 'ukraine', 'poland': 'poland', 'thailand': 'india', 'portugal': 'portugal', 'united states': 'united states', 'france': 'france', 'philippines': 'philippines', 'south korea': 'morocco', 'spain': 'spain', 'tunisia': 'morocco', 'hungary': 'hungary', 'armenia': 'armenia', 'denmark': 'denmark', 'brazil': 'brazil', 'australia': 'australia', 'taiwan': 'china', 'syria': 'lebanon', 'malaysia': 'india', 'nigeria': 'morocco', 'jamaica': 'jamaica', 'ireland': 'morocco', 'serbia': 'poland', 'colombia': 'colombia', 'sweden': 'morocco', 'switzerland': 'italy', 'japan': 'japan', 'romania': 'romania', 'peru': 'argentina', 'vietnam': 'switzerland', 'argentina': 'argentina', 'algeria': 'morocco', 'mongolia': 'mongolia', 'bulgaria': 'bulgaria', 'congo': 'congo', 'ethiopia': 'morocco', 'turkiye': 'armenia', 'indonesia': 'indonesia', 'belgium': 'belgium', 'canada': 'france'}\n"
     ]
    }
   ],
   "source": [
    "print(same_varia, tot_count, same_varia/tot_count)\n",
    "print(same_orig_tradi, 1- same_orig_tradi/496) ##501\n",
    "print(dict_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fceb5c5a",
   "metadata": {},
   "source": [
    "## Counting recipes with less than 50 tokens & repetition of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b139bf19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:22<00:00, 22.68it/s]\n"
     ]
    }
   ],
   "source": [
    "too_short = 0\n",
    "recipe_count = 0\n",
    "window = 3\n",
    "repeat_prop = []\n",
    "country_repeat = []\n",
    "for k in tqdm(range(len(filenames))):\n",
    "    recette = filenames[k]\n",
    "    file_path = data_path + recette\n",
    "    with open(file_path) as json_file:\n",
    "        recipe_dict = json.load(json_file)\n",
    "\n",
    "    country_orig = recipe_dict['Country'].lower()\n",
    "    if 'same_country_novelty' in recipe_dict['LLM_gen']:\n",
    "        llm_recipe_ids = list(recipe_dict['LLM_gen']['same_country_novelty'].keys())\n",
    "        for recipe in llm_recipe_ids:\n",
    "            recipe = recipe_dict['LLM_gen']['same_country_novelty'][recipe]['Instructions']\n",
    "            tokens = recipe.split(' ')\n",
    "            if len(tokens) <= 50:\n",
    "                too_short += 1\n",
    "            recipe_count += 1\n",
    "            repeats = 0\n",
    "            for i, token in enumerate(tokens):\n",
    "                # look ahead up to 3 tokens\n",
    "                if token in tokens[i+1:i+1+window]:\n",
    "                    repeats += 1\n",
    "            repeat_prop.append(repeats/len(tokens))\n",
    "            if repeats/len(tokens) > 0.1:\n",
    "                country_repeat.append(country_orig)\n",
    "\n",
    "    \n",
    "    \n",
    "    varia_countries = list(recipe_dict['LLM_gen']['variation_novelty'].keys())\n",
    "    for varia in varia_countries:\n",
    "        llm_recipe_varia_ids = list(recipe_dict['LLM_gen']['variation_novelty'][varia].keys())\n",
    "        for i in range(len(llm_recipe_varia_ids)):\n",
    "            recipe = recipe_dict['LLM_gen']['variation_novelty'][varia][llm_recipe_varia_ids[i]]['Instructions']\n",
    "            tokens = recipe.split(' ')\n",
    "            if len(tokens) <= 50:\n",
    "                too_short += 1\n",
    "            recipe_count += 1\n",
    "            repeats = 0\n",
    "            for i, token in enumerate(tokens):\n",
    "                # look ahead up to 3 tokens\n",
    "                if token in tokens[i+1:i+1+window]:\n",
    "                    repeats += 1\n",
    "            repeat_prop.append(repeats/len(tokens))\n",
    "            if repeats/len(tokens) > 0.1:\n",
    "                country_repeat.append(country_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b394623d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.028743192804258706\n",
      "0.005526344479807427\n",
      "Counter({'mexico': 13, 'italy': 11, 'france': 11, 'united states': 9, 'china': 7, 'thailand': 7, 'india': 7, 'switzerland': 7, 'greece': 6, 'germany': 5, 'morocco': 4, 'russia': 4, 'spain': 3, 'sweden': 3, 'brazil': 3, 'japan': 3, 'south korea': 3, 'turkiye': 3, 'ireland': 3, 'portugal': 2, 'netherlands': 2, 'philippines': 2, 'vietnam': 2, 'cuba': 2, 'ukraine': 1, 'australia': 1, 'taiwan': 1, 'malaysia': 1, 'tunisia': 1, 'algeria': 1, 'congo': 1, 'serbia': 1, 'ethiopia': 1})\n"
     ]
    }
   ],
   "source": [
    "print(too_short/recipe_count)\n",
    "print(sum(repeat_prop)/len(repeat_prop))\n",
    "print(Counter(country_repeat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6094d111",
   "metadata": {},
   "source": [
    "## Counting Title where recipe name or country is not in the title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8673e8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:12<00:00, 40.32it/s]\n"
     ]
    }
   ],
   "source": [
    "recipe_presence = 0\n",
    "ingredient_presence = 0\n",
    "total = 0\n",
    "\n",
    "for k in tqdm(range(len(filenames))):\n",
    "    recette = filenames[k]\n",
    "    file_path = data_path + recette\n",
    "    with open(file_path) as json_file:\n",
    "        recipe_dict = json.load(json_file)\n",
    "\n",
    "    country_orig = recipe_dict['Country'].lower()\n",
    "    recipe_name = recipe_dict['Recipe_Name'].lower()\n",
    "    recipe_name = recipe_name.split(' ')\n",
    "    #print(recipe_name)\n",
    "    if 'same_country_novelty' in recipe_dict['LLM_gen']:\n",
    "        same_novelty_dict = recipe_dict['LLM_gen']['same_country_novelty']\n",
    "        same_key_list = list(same_novelty_dict.keys())\n",
    "\n",
    "        for key in same_key_list:\n",
    "            recipe_prop = 0\n",
    "            ingredient_prop = 0\n",
    "            title = same_novelty_dict[key]['Title']\n",
    "            ingredient_list = same_novelty_dict[key]['Ingredients']\n",
    "            for noun in recipe_name:\n",
    "                if noun in title:\n",
    "                    recipe_prop += 1\n",
    "                if any(noun in ingredient for ingredient in ingredient_list):\n",
    "                    ingredient_prop += 1\n",
    "            if recipe_prop / len(recipe_name) > 0.5:\n",
    "                recipe_presence += 1\n",
    "            if ingredient_prop / len(recipe_name) > 0.5:\n",
    "                ingredient_presence += 1\n",
    "            total += 1\n",
    "\n",
    "    varia_novelty_dict = recipe_dict['LLM_gen']['variation_novelty']\n",
    "    varia_country_keys = list(varia_novelty_dict.keys())\n",
    "\n",
    "    for varia_country in varia_country_keys:\n",
    "        country_v = varia_country.split(\"_\", 1)[1]\n",
    "        key_list = list(varia_novelty_dict[varia_country].keys())\n",
    "        for key in key_list:\n",
    "            title = varia_novelty_dict[varia_country][key]['Title']\n",
    "            ingredient_list = varia_novelty_dict[varia_country][key]['Ingredients']\n",
    "            for noun in recipe_name:\n",
    "                if noun in title:\n",
    "                    recipe_prop += 1\n",
    "                if any(noun in ingredient for ingredient in ingredient_list):\n",
    "                    ingredient_prop += 1\n",
    "            if recipe_prop / len(recipe_name) > 0.5:\n",
    "                recipe_presence += 1\n",
    "            if ingredient_prop / len(recipe_name) > 0.5:\n",
    "                ingredient_presence += 1\n",
    "            total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e48b904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of recipe name that are in the title of the recipe explicitely 0.9181504823675783\n",
      "Proportion of recipe that are in the list of ingredients 0.8672622325562422\n"
     ]
    }
   ],
   "source": [
    "print('Proportion of recipe name that are in the title of the recipe explicitely', recipe_presence/total)\n",
    "print('Proportion of recipe that are in the list of ingredients', ingredient_presence/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755be6ed",
   "metadata": {},
   "source": [
    "## From which country the recipes are coming from?\n",
    "Based on the common ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0e19561",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ingredients_country = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eceec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the list of ingredients per country for humans -- Execute one only\n",
    "ingredient_path = './country_ingredients.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63ad92fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists — loading it.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(ingredient_path):\n",
    "    print(\"File not found — generating it now...\")\n",
    "    \n",
    "    for k in tqdm(range(len(filenames))):\n",
    "        recette = filenames[k]\n",
    "        file_path = data_path + recette\n",
    "        with open(file_path) as json_file:\n",
    "            recipe_dict = json.load(json_file)\n",
    "\n",
    "        #Appending first the list of ingredients of the associated country of origin\n",
    "        country_orig = recipe_dict['Country'].lower()\n",
    "        dict_ingredients_country[country_orig] = recipe_dict['Reference_Base']['AllIngredients']\n",
    "\n",
    "        #Going through training/var/test to append also list of ingredients\n",
    "        id_train = recipe_dict['Train_Variations']\n",
    "        for id in id_train:\n",
    "            country_v = recipe_dict['Train_Variations'][id]['country'].lower()\n",
    "            str_ingredients = recipe_dict['Train_Variations'][id]['ingredient_list']\n",
    "            ingredient_list = ast.literal_eval(str_ingredients)\n",
    "            if country_v not in dict_ingredients_country.keys():\n",
    "                dict_ingredients_country[country_v] = ingredient_list\n",
    "            else:\n",
    "                dict_ingredients_country[country_v].extend(ingredient_list)\n",
    "\n",
    "        id_valid = recipe_dict['Valid_Variations']\n",
    "        for id in id_valid:\n",
    "            country_v = recipe_dict['Valid_Variations'][id]['country'].lower()\n",
    "            str_ingredients = recipe_dict['Valid_Variations'][id]['ingredient_list']\n",
    "            ingredient_list = ast.literal_eval(str_ingredients)\n",
    "            if country_v not in dict_ingredients_country.keys():\n",
    "                dict_ingredients_country[country_v] = ingredient_list\n",
    "            else:\n",
    "                dict_ingredients_country[country_v].extend(ingredient_list)\n",
    "\n",
    "        id_test = recipe_dict['Test_Variations']\n",
    "        for id in id_test:\n",
    "            country_v = recipe_dict['Test_Variations'][id]['country'].lower()\n",
    "            str_ingredients = recipe_dict['Test_Variations'][id]['ingredient_list']\n",
    "            ingredient_list = ast.literal_eval(str_ingredients)\n",
    "            if country_v not in dict_ingredients_country.keys():\n",
    "                dict_ingredients_country[country_v] = ingredient_list\n",
    "            else:\n",
    "                dict_ingredients_country[country_v].extend(ingredient_list)\n",
    "        \n",
    "        with open(ingredient_path, \"w\") as f:\n",
    "            json.dump(dict_ingredients_country, f, indent=2)\n",
    "else:\n",
    "    print(\"File already exists — loading it.\")\n",
    "    with open(ingredient_path, \"r\") as f:\n",
    "        dict_ingredients_country = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba5fdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_match(list_orig, dict_of_lists):\n",
    "\n",
    "    best_key = None\n",
    "    best_count = 0\n",
    "\n",
    "    set_orig = set(list_orig)  # use set for fast intersection\n",
    "\n",
    "    for key, values in dict_of_lists.items():\n",
    "        common = set_orig.intersection(set(values))\n",
    "        count = len(common)\n",
    "\n",
    "        if count > best_count:\n",
    "            best_count = count\n",
    "            best_key = key\n",
    "\n",
    "    return best_key, best_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97586da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_ingredients_spacy(lines, list_countries):\n",
    "    \"\"\"\n",
    "    Keep only nouns (and noun→noun compounds), remove countries.\n",
    "    lines: list of raw ingredient strings (with leading \"- \" etc.)\n",
    "    list_countries: list of country names to filter out (any case)\n",
    "    \"\"\"\n",
    "    # normalize country names to lowercase lemmas for filtering\n",
    "    countries = {c.strip().lower() for c in list_countries}\n",
    "\n",
    "    cleaned = []\n",
    "    for raw in lines:\n",
    "        # 1) remove leading \"- \" and lowercase for uniformity\n",
    "        s = re.sub(r'^\\s*-\\s*', '', raw).strip()\n",
    "\n",
    "        doc = nlp(s)\n",
    "        phrases = []\n",
    "        for tok in doc:\n",
    "            # head noun or proper noun\n",
    "            if tok.pos_ in {\"NOUN\", \"PROPN\"} and tok.dep_ not in {\"compound\"}:\n",
    "                # build phrase: include left-side noun compounds (NOUN/PROPN with dep_ == 'compound')\n",
    "                parts = []\n",
    "                for left in tok.lefts:\n",
    "                    if left.dep_ == \"compound\" and left.pos_ in {\"NOUN\", \"PROPN\"}:\n",
    "                        parts.append(left.lemma_.lower())\n",
    "                parts.append(tok.lemma_.lower())\n",
    "\n",
    "                # drop any country tokens inside the phrase\n",
    "                parts = [p for p in parts if p not in countries]\n",
    "                if parts:\n",
    "                    phrases.append(\" \".join(parts))\n",
    "\n",
    "        # 4) simple heuristic:\n",
    "        #    if we found multiple noun phrases, keep the longest one,\n",
    "        #    else keep the first, else empty string\n",
    "        if phrases:\n",
    "            best = max(phrases, key=lambda x: len(x))\n",
    "            cleaned.append(best)\n",
    "        else:\n",
    "            cleaned.append(\"\")\n",
    "\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f762ab28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 484/484 [00:45<00:00, 10.60it/s]\n"
     ]
    }
   ],
   "source": [
    "dict_comparision = defaultdict(list)\n",
    "avg_best_match_ingre = []\n",
    "same_country = 0\n",
    "total = 0\n",
    "no_match = 0 \n",
    "total_m = 0\n",
    "list_countries_filter = list(dict_ingredients_country.keys())\n",
    "\n",
    "for k in tqdm(range(len(filenames))):\n",
    "    recette = filenames[k]\n",
    "    file_path = data_path + recette\n",
    "    with open(file_path) as json_file:\n",
    "        recipe_dict = json.load(json_file)\n",
    "\n",
    "    country_orig = recipe_dict['Country'].lower()\n",
    "    if 'same_country_novelty' in recipe_dict['LLM_gen']:\n",
    "        same_novelty_dict = recipe_dict['LLM_gen']['same_country_novelty']\n",
    "        same_key_list = list(same_novelty_dict.keys())\n",
    "        for key in same_key_list:\n",
    "            ingredient_list = same_novelty_dict[key]['Ingredients']\n",
    "            ingredient_list = clean_ingredients_spacy(ingredient_list, list_countries_filter)\n",
    "            best_country, best_count = find_best_match(ingredient_list, dict_ingredients_country)\n",
    "            if best_country != None:\n",
    "                avg_best_match_ingre.append(best_count)\n",
    "                if country_orig not in dict_comparision.keys():\n",
    "                    dict_comparision[country_orig] = [best_country]\n",
    "                else:\n",
    "                    dict_comparision[country_orig].append(best_country)\n",
    "\n",
    "                if best_country == country_orig:\n",
    "                    same_country +=1\n",
    "                total_m += 1\n",
    "                total += 1\n",
    "            else:\n",
    "                no_match += 1\n",
    "                total += 1\n",
    "\n",
    "    \n",
    "    varia_novelty_dict = recipe_dict['LLM_gen']['variation_novelty']\n",
    "    varia_country_keys = list(varia_novelty_dict.keys())\n",
    "\n",
    "    for varia_country in varia_country_keys:\n",
    "        country_v = varia_country.split(\"_\", 1)[1]\n",
    "        key_list = list(varia_novelty_dict[varia_country].keys())\n",
    "        for key in key_list:\n",
    "            title = varia_novelty_dict[varia_country][key]['Title']\n",
    "            ingredient_list = varia_novelty_dict[varia_country][key]['Ingredients']\n",
    "            ingredient_list = clean_ingredients_spacy(ingredient_list, list_countries_filter)\n",
    "            best_country, best_count = find_best_match(ingredient_list, dict_ingredients_country)\n",
    "            if best_country != None:\n",
    "                avg_best_match_ingre.append(best_count)\n",
    "                if country_v not in dict_comparision.keys():\n",
    "                    dict_comparision[country_v] = [best_country]\n",
    "                else:\n",
    "                    dict_comparision[country_v].append(best_country)\n",
    "                \n",
    "                if best_country == country_v:\n",
    "                    same_country +=1\n",
    "                total+=1\n",
    "            else:\n",
    "                no_match += 1\n",
    "                total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73695321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of recipes where ingredients match their expected country :  0.005191833861316438\n",
      "Proportion of absolutely not match ingredients -- the recipes used 0 ever seen ingredients :  0.944385779655051\n",
      "Most common countries: [('china', 316), ('chile', 198), ('united states', 71), ('australia', 69), ('mexico', 67), ('mongolia', 61), ('russia', 58), ('india', 54), ('hungary', 52), ('sweden', 37)]\n"
     ]
    }
   ],
   "source": [
    "print('Proportion of recipes where ingredients match their expected country : ', same_country/total)\n",
    "print('Proportion of absolutely not match ingredients -- the recipes used 0 ever seen ingredients : ', no_match/total)\n",
    "all_items = [item for sublist in dict_comparision.values() for item in sublist]\n",
    "counts = Counter(all_items)\n",
    "#most_common_item, frequency = counts.most_common(1)[0]\n",
    "top5 = counts.most_common(10)\n",
    "print(f\"Most common countries:\", top5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a40571",
   "metadata": {},
   "source": [
    "# Inrgedients from Cosine Similiarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64d4bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredient_path = './country_ingredients.json'\n",
    "with open(ingredient_path, \"r\") as f:\n",
    "    dict_ingredients_country = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab9afe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def fit_tfidf(country_to_ingredients, lowercase=True, smooth_idf=True, sublinear_tf=False):\n",
    "    # Build vocab\n",
    "    vocab = set()\n",
    "    docs = []\n",
    "    for ingr_list in country_to_ingredients.values():\n",
    "        doc = [x.lower() for x in ingr_list] if lowercase else list(ingr_list)\n",
    "        docs.append(doc)\n",
    "        vocab.update(doc)\n",
    "\n",
    "    ingredient_to_id = {ing: i for i, ing in enumerate(sorted(vocab))}\n",
    "    V = len(ingredient_to_id)\n",
    "    N = len(docs)\n",
    "\n",
    "    # Document frequency\n",
    "    df = np.zeros(V, dtype=float)\n",
    "    for doc in docs:\n",
    "        for ing in set(doc):\n",
    "            df[ingredient_to_id[ing]] += 1.0\n",
    "\n",
    "    # IDF\n",
    "    # classic smooth: idf = log((N+1)/(df+1)) + 1\n",
    "    if smooth_idf:\n",
    "        idf = np.log((N + 1.0) / (df + 1.0)) + 1.0\n",
    "    else:\n",
    "        idf = np.log(N / np.maximum(df, 1.0))\n",
    "\n",
    "    # Build TF-IDF matrix for the training countries\n",
    "    countries = list(country_to_ingredients.keys())\n",
    "    X = np.zeros((N, V), dtype=float)\n",
    "\n",
    "    for r, doc in enumerate(docs):\n",
    "        tf = Counter(doc)\n",
    "        for ing, c in tf.items():\n",
    "            j = ingredient_to_id[ing]\n",
    "            val = 1.0 + np.log(c) if sublinear_tf else float(c)\n",
    "            X[r, j] = val\n",
    "\n",
    "    X *= idf  # apply idf\n",
    "    return countries, X, ingredient_to_id, idf\n",
    "\n",
    "\n",
    "def transform_tfidf(ingredients, ingredient_to_id, idf, lowercase=True, sublinear_tf=False):\n",
    "    V = len(ingredient_to_id)\n",
    "    v = np.zeros(V, dtype=float)\n",
    "\n",
    "    ingredients = [x.lower() for x in ingredients] if lowercase else list(ingredients)\n",
    "    tf = Counter(ingredients)\n",
    "\n",
    "    for ing, c in tf.items():\n",
    "        j = ingredient_to_id.get(ing)\n",
    "        if j is None:\n",
    "            continue  # OOV ingredient -> ignore\n",
    "        val = 1.0 + np.log(c) if sublinear_tf else float(c)\n",
    "        v[j] = val\n",
    "\n",
    "    v *= idf\n",
    "    return v\n",
    "\n",
    "def cosine_vec_to_matrix(v, X, eps=1e-12):\n",
    "    vnorm = np.linalg.norm(v) + eps\n",
    "    Xnorm = np.linalg.norm(X, axis=1) + eps\n",
    "    return (X @ v) / (Xnorm * vnorm)\n",
    "\n",
    "def cosine_matrix(X, eps=1e-12):\n",
    "    # pairwise cosine sim for all countries\n",
    "    norms = np.linalg.norm(X, axis=1, keepdims=True)\n",
    "    Xn = X / (norms + eps)\n",
    "    return Xn @ Xn.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d566b0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries, X, ingredient_to_id, idf = fit_tfidf(dict_ingredients_country, sublinear_tf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e5a7996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'mongolia': 3, 'france': 7, 'greece': 3, 'chile': 1, 'japan': 2, 'angola': 1, 'netherlands': 2, 'canada': 2, 'mexico': 1, 'russia': 2, 'israel': 1, 'malaysia': 4, 'lebanon': 4, 'estonia': 4, 'hungary': 13, 'iraq': 1, 'dominican republic': 1, 'indonesia': 3, 'united states': 2, 'india': 6, 'singapore': 1, 'vietnam': 1, 'ecuador': 1, 'thailand': 1, 'cuba': 2, 'tunisia': 1, 'turkiye': 5, 'paraguay': 2, 'uzbekistan': 2, 'switzerland': 1, 'liechtenstein': 1, 'panama': 1, 'albania': 1, 'ukraine': 2, 'bolivia': 2, 'egypt': 2, 'moldova': 1, 'azerbaijan': 1, 'romania': 2, 'qatar': 2, 'norway': 3, 'mauritius': 1, 'tonga': 1, 'guam': 3, 'mozambique': 1, 'oman': 1, 'haiti': 1, 'china': 1, 'ghana': 1, 'lithuania': 2, 'belarus': 1, 'mauritania': 1, 'uruguay': 1, 'luxembourg': 2, 'trinidad and tobago': 1, 'belize': 1, 'spain': 1, 'pakistan': 1, 'chad': 1, 'brunei': 2, 'bulgaria': 1, 'antigua and barbuda': 1, 'afghanistan': 1, 'liberia': 1, 'yemen': 1, 'bahamas': 1, 'guernsey': 1, 'iceland': 1})\n"
     ]
    }
   ],
   "source": [
    "dict_countries = defaultdict(int)\n",
    "## Most similar countries in DB\n",
    "S = cosine_matrix(X) # S[i,j] is cosine similarity between countries[i] and countries[j]\n",
    "\n",
    "for i in range(len(countries)):\n",
    "    country_vector = S[i].copy()\n",
    "    country_vector[i] = -1 ## Just to make it so we don't select country[i] everytime since sim = 1\n",
    "    best_matching_index = np.argmax(country_vector)\n",
    "    best_matching_country = countries[best_matching_index]\n",
    "    dict_countries[best_matching_country] += 1\n",
    "print(dict_countries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4eb5f205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common countries: [('hungary', 13), ('france', 7), ('india', 6), ('turkiye', 5), ('malaysia', 4), ('lebanon', 4), ('estonia', 4), ('mongolia', 3), ('greece', 3), ('indonesia', 3)]\n"
     ]
    }
   ],
   "source": [
    "top_k = 10\n",
    "most_common = sorted(dict_countries.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "print(f\"Most common countries:\", most_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5af98244",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/496 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 496/496 [37:58<00:00,  4.59s/it]\n"
     ]
    }
   ],
   "source": [
    "same_country = 0\n",
    "same_country_2 = 0\n",
    "same_ = 0\n",
    "total = 0\n",
    "total_tot = 0\n",
    "list_countries_filter = list(dict_ingredients_country.keys())\n",
    "countries, X, ingredient_to_id, idf = fit_tfidf(dict_ingredients_country, sublinear_tf=True)\n",
    "dict_countries_mismatch = defaultdict(int)\n",
    "\n",
    "for k in tqdm(range(len(filenames))):\n",
    "    recette = filenames[k]\n",
    "    file_path = data_path + recette\n",
    "    with open(file_path) as json_file:\n",
    "        recipe_dict = json.load(json_file)\n",
    "\n",
    "    country_orig = recipe_dict['Country'].lower()\n",
    "    if 'same_country_novelty' in recipe_dict['LLM_gen']:\n",
    "        same_novelty_dict = recipe_dict['LLM_gen']['same_country_novelty']\n",
    "        same_key_list = list(same_novelty_dict.keys())\n",
    "        for key in same_key_list:\n",
    "            ingredient_list = same_novelty_dict[key]['Ingredients']\n",
    "            ingredient_list = clean_ingredients_spacy(ingredient_list, list_countries_filter)\n",
    "            v_new = transform_tfidf(ingredient_list, ingredient_to_id, idf, sublinear_tf=True)\n",
    "            sims = cosine_vec_to_matrix(v_new, X)\n",
    "            best_match, _ = sorted(zip(countries, sims), key=lambda x: -x[1])[0]\n",
    "\n",
    "            if best_match == country_orig:\n",
    "                same_country += 1\n",
    "                same_country_2 += 1\n",
    "                same_ += 1\n",
    "            else:\n",
    "                dict_countries_mismatch[best_match] += 1\n",
    "            total += 1\n",
    "            total_tot += 1\n",
    "\n",
    "    varia_novelty_dict = recipe_dict['LLM_gen']['variation_novelty']\n",
    "    varia_country_keys = list(varia_novelty_dict.keys())\n",
    "\n",
    "    for varia_country in varia_country_keys:\n",
    "        country_v = varia_country.split(\"_\", 1)[1]\n",
    "        key_list = list(varia_novelty_dict[varia_country].keys())\n",
    "        for key in key_list:\n",
    "            title = varia_novelty_dict[varia_country][key]['Title']\n",
    "            ingredient_list = varia_novelty_dict[varia_country][key]['Ingredients']\n",
    "            ingredient_list = clean_ingredients_spacy(ingredient_list, list_countries_filter)\n",
    "            v_new = transform_tfidf(ingredient_list, ingredient_to_id, idf, sublinear_tf=True)\n",
    "            sims = cosine_vec_to_matrix(v_new, X)\n",
    "            best_match, _ = sorted(zip(countries, sims), key=lambda x: -x[1])[0]\n",
    "\n",
    "            if best_match == country_orig:\n",
    "                same_country_2 += 1\n",
    "            elif best_match == country_v:\n",
    "                same_ += 1\n",
    "            else:\n",
    "                dict_countries_mismatch[best_match] += 1\n",
    "            total_tot += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d70a78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of recipes where ingredients match their origin country :  0.057305858310626706\n",
      "Proportion of recipes where ingredients match their origin country when varia:  0.03952535354658773\n",
      "Proportion of inredients from varia match country varia :  0.03243202115214518\n"
     ]
    }
   ],
   "source": [
    "print('Proportion of recipes where ingredients match their origin country : ', same_country/total)\n",
    "print('Proportion of recipes where ingredients match their origin country when varia: ', same_country_2/total_tot)\n",
    "print('Proportion of inredients from varia match country varia : ', same_/(total_tot-total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d1e3ceb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common countries: [('china', 28194), ('belarus', 11537), ('chad', 8285), ('liberia', 7816), ('guyana', 6693), ('finland', 6012), ('jamaica', 5209), ('qatar', 5015), ('dominican republic', 4910), ('estonia', 4602)]\n"
     ]
    }
   ],
   "source": [
    "top_k = 10\n",
    "most_common = sorted(dict_countries_mismatch.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "print(f\"Most common countries:\", most_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "734f5b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ingr(ingredient, authorized_pos=['NOUN']):\n",
    "\n",
    "    doc = nlp(ingredient)\n",
    "    token_list = [token.text for token in doc if token.pos_ in authorized_pos]\n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d8cf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do for Humans too here\n",
    "same_country = 0\n",
    "same_country_2 = 0\n",
    "same_country_v = 0\n",
    "total = 0\n",
    "list_countries_filter = list(dict_ingredients_country.keys())\n",
    "countries, X, ingredient_to_id, idf = fit_tfidf(dict_ingredients_country, sublinear_tf=True)\n",
    "dict_countries_mismatch = defaultdict(int)\n",
    "total_tot = 0\n",
    "\n",
    "for k in tqdm(range(len(filenames))):\n",
    "    recette = filenames[k]\n",
    "    file_path = data_path + recette\n",
    "    with open(file_path) as json_file:\n",
    "        recipe_dict = json.load(json_file)\n",
    "\n",
    "    country_orig = recipe_dict['Country'].lower()\n",
    "    train_recipe_ids = list(recipe_dict['Train_Variations'].keys())\n",
    "    for i in range(len(train_recipe_ids)):\n",
    "        recipe = recipe_dict['Train_Variations'][train_recipe_ids[i]]\n",
    "        country_t = recipe['country']\n",
    "        ingredient_train = recipe['ingredient_list']\n",
    "        human_ingredient_list = []\n",
    "        for ingredient in ingredient_train:\n",
    "            human_ingredient_list.extend(clean_ingr(ingredient))\n",
    "        human_ingredient_list = list(set(human_ingredient_list))\n",
    "\n",
    "        v_new = transform_tfidf(human_ingredient_list, ingredient_to_id, idf, sublinear_tf=True)\n",
    "        sims = cosine_vec_to_matrix(v_new, X)\n",
    "        best_match, _ = sorted(zip(countries, sims), key=lambda x: -x[1])[0]\n",
    "        if country_t == country_orig:\n",
    "            total += 1\n",
    "        if best_match == country_orig:\n",
    "            if country_t == country_orig:\n",
    "                same_country_2 += 1\n",
    "            same_country += 1\n",
    "            total_tot += 1\n",
    "        elif best_match == country_t:\n",
    "            same_country_v += 1\n",
    "            total_tot += 1\n",
    "        else:\n",
    "            dict_countries_mismatch[best_match] += 1\n",
    "            total_tot += 1\n",
    "\n",
    "    valid_recipe_ids = list(recipe_dict['Valid_Variations'].keys())\n",
    "    for i in range(len(valid_recipe_ids)):\n",
    "        recipe = recipe_dict['Valid_Variations'][valid_recipe_ids[i]]\n",
    "        country_t = recipe['country']\n",
    "        ingredient_valid = recipe['ingredient_list']\n",
    "        \n",
    "        human_ingredient_list = []\n",
    "        for ingredient in ingredient_valid:\n",
    "            human_ingredient_list.extend(clean_ingr(ingredient))\n",
    "        human_ingredient_list = list(set(human_ingredient_list))\n",
    "        v_new = transform_tfidf(human_ingredient_list, ingredient_to_id, idf, sublinear_tf=True)\n",
    "        sims = cosine_vec_to_matrix(v_new, X)\n",
    "        best_match, _ = sorted(zip(countries, sims), key=lambda x: -x[1])[0]\n",
    "\n",
    "        if country_t == country_orig:\n",
    "            total += 1\n",
    "        if best_match == country_orig:\n",
    "            if country_t == country_orig:\n",
    "                same_country_2 += 1\n",
    "            same_country += 1\n",
    "            total_tot += 1\n",
    "        elif best_match == country_t:\n",
    "            same_country_v += 1\n",
    "            total_tot += 1\n",
    "        else:\n",
    "            dict_countries_mismatch[best_match] += 1\n",
    "            total_tot += 1\n",
    "\n",
    "\n",
    "    test_recipe_ids = list(recipe_dict['Test_Variations'].keys())\n",
    "    for i in range(len(test_recipe_ids)):\n",
    "        recipe = recipe_dict['Test_Variations'][test_recipe_ids[i]]\n",
    "        country_t = recipe['country']\n",
    "        ingredient_test = recipe['ingredient_list']\n",
    "        \n",
    "        human_ingredient_list = []\n",
    "        for ingredient in ingredient_test:\n",
    "            human_ingredient_list.extend(clean_ingr(ingredient))\n",
    "        human_ingredient_list = list(set(human_ingredient_list))\n",
    "\n",
    "        v_new = transform_tfidf(human_ingredient_list, ingredient_to_id, idf, sublinear_tf=True)\n",
    "        sims = cosine_vec_to_matrix(v_new, X)\n",
    "        best_match, _ = sorted(zip(countries, sims), key=lambda x: -x[1])[0]\n",
    "\n",
    "        if country_t == country_orig:\n",
    "            total += 1\n",
    "        if best_match == country_orig:\n",
    "            if country_t == country_orig:\n",
    "                same_country_2 += 1\n",
    "            same_country += 1\n",
    "            total_tot += 1\n",
    "        elif best_match == country_t:\n",
    "            same_country_v += 1\n",
    "            total_tot += 1\n",
    "        else:\n",
    "            dict_countries_mismatch[best_match] += 1\n",
    "            total_tot += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c88b86d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of recipes where ingredients match their origin country :  0.06141732283464567\n",
      "Proportion of recipes where ingredients match their origin country :  0.057351168264538725\n",
      "Proportion of recipes where ingredients match their origin country :  0.019633733279751996\n"
     ]
    }
   ],
   "source": [
    "print('Proportion of recipes where ingredients match their origin country : ', same_country_2/total)\n",
    "print('Proportion of recipes where ingredients match their origin country : ', same_country/total_tot)\n",
    "print('Proportion of recipes where ingredients match their origin country : ', same_country_v/total_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "393ba71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common countries: [('china', 13889), ('haiti', 998), ('peru', 775), ('mongolia', 416)]\n"
     ]
    }
   ],
   "source": [
    "top_k = 10\n",
    "most_common = sorted(dict_countries_mismatch.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "print(f\"Most common countries:\", most_common)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78039313",
   "metadata": {},
   "source": [
    "# Most common ingredients in LLMs production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe082376",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/496 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 496/496 [36:46<00:00,  4.45s/it]\n"
     ]
    }
   ],
   "source": [
    "list_countries_filter = list(dict_ingredients_country.keys())\n",
    "countries, X, ingredient_to_id, idf = fit_tfidf(dict_ingredients_country, sublinear_tf=True)\n",
    "dict_ingredients = defaultdict(int)\n",
    "\n",
    "for k in tqdm(range(len(filenames))):\n",
    "    recette = filenames[k]\n",
    "    file_path = data_path + recette\n",
    "    with open(file_path) as json_file:\n",
    "        recipe_dict = json.load(json_file)\n",
    "\n",
    "    country_orig = recipe_dict['Country'].lower()\n",
    "    if 'same_country_novelty' in recipe_dict['LLM_gen']:\n",
    "        same_novelty_dict = recipe_dict['LLM_gen']['same_country_novelty']\n",
    "        same_key_list = list(same_novelty_dict.keys())\n",
    "        for key in same_key_list:\n",
    "            ingredient_list = same_novelty_dict[key]['Ingredients']\n",
    "            ingredient_list = clean_ingredients_spacy(ingredient_list, list_countries_filter)\n",
    "            for ingredient in ingredient_list:\n",
    "                dict_ingredients[ingredient] += 1\n",
    "\n",
    "    varia_novelty_dict = recipe_dict['LLM_gen']['variation_novelty']\n",
    "    varia_country_keys = list(varia_novelty_dict.keys())\n",
    "\n",
    "    for varia_country in varia_country_keys:\n",
    "        country_v = varia_country.split(\"_\", 1)[1]\n",
    "        key_list = list(varia_novelty_dict[varia_country].keys())\n",
    "        for key in key_list:\n",
    "            title = varia_novelty_dict[varia_country][key]['Title']\n",
    "            ingredient_list = varia_novelty_dict[varia_country][key]['Ingredients']\n",
    "            ingredient_list = clean_ingredients_spacy(ingredient_list, list_countries_filter)\n",
    "            for ingredient in ingredient_list:\n",
    "                dict_ingredients[ingredient] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9898baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common countries: [('salt', 32383), ('oil', 30303), ('butter', 26741), ('sugar', 26307), ('powder', 25519), ('vanilla extract', 22283), ('pepper', 20359), ('onion', 20002), ('ground', 17875), ('parsley', 17723), ('ground cumin', 14213), ('lemon juice', 14073), ('cheese', 12621), ('ground cinnamon', 12488), ('salt taste', 11898), ('', 10996), ('oregano', 10430), ('water', 10154), ('egg', 10055), ('milk', 9478)]\n"
     ]
    }
   ],
   "source": [
    "top_k = 20\n",
    "most_common = sorted(dict_ingredients.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "print(f\"Most common countries:\", most_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571f1bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
